{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, cv2, glob, random\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import asarray, clip\n",
    "from tensorflow.keras import regularizers, layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import segmentation_models as sm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dense\n",
    "from keras.layers import Dropout, Lambda, Activation, AveragePooling2D, Flatten, Concatenate, GlobalAveragePooling2D, Add\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.regularizers import l2, l1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========= MODEL KOMPARASI UNTUK JURNAL 2  ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN 8 ===== Long, 2015\n",
    "def fcn_8(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1_1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n",
    "\n",
    "    conv2_1 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2_1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n",
    "\n",
    "    conv3_1 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3_2 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3_1)\n",
    "    conv3_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3_2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3_3)\n",
    "\n",
    "    conv4_1 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4_2 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4_1)\n",
    "    conv4_3 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4_2)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4_3)\n",
    "\n",
    "    conv5_1 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5_2 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5_1)\n",
    "    conv5_3 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5_2)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5_3)\n",
    "\n",
    "    # Decoder\n",
    "    fc6 = Conv2D(4096, (7, 7), activation='relu', padding='same')(pool5)\n",
    "    dropout6 = Dropout(rate=0.5)(fc6)\n",
    "\n",
    "    fc7 = Conv2D(4096, (1, 1), activation='relu', padding='same')(dropout6)\n",
    "    dropout7 = Dropout(rate=0.5)(fc7)\n",
    "\n",
    "    score_fr = Conv2D(num_classes, (1, 1), padding='valid')(dropout7)\n",
    "\n",
    "    score_pool4 = Conv2D(num_classes, (1, 1), padding='valid')(pool4)\n",
    "    score_pool4c = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same')(score_pool4)\n",
    "\n",
    "    score_pool3 = Conv2D(num_classes, (1, 1), padding='valid')(pool3)\n",
    "    score_pool3c = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same')(score_pool3)\n",
    "    \n",
    "    score_pool2 = Conv2D(num_classes, (1, 1), padding='valid')(pool2)\n",
    "    score_pool2c = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same')(score_pool2)\n",
    "    \n",
    "    score_pool1 = Conv2D(num_classes, (1, 1), padding='valid')(pool1)\n",
    "    score_pool1c = Conv2DTranspose(num_classes, kernel_size=(4, 4), strides=(2, 2), padding='same')(score_pool1)\n",
    "        \n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(score_pool1c)\n",
    "\n",
    "    # Define the model\n",
    "    modelF = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return modelF\n",
    "\n",
    "# modelF = fcn_8(input_shape=(256, 256, 1), num_classes=4)\n",
    "modelF = fcn_8(input_shape=(512, 512, 3), num_classes=3)\n",
    "modelF.compile(optimizer='adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "modelF.summary()\n",
    "\n",
    "# save the model for future use\n",
    "# modelF.save('data/model_save/FCN8.hdfs')\n",
    "# modelF.save('data/model_save/FCN8_256.hdfs')\n",
    "modelF.save('data/model_save/FCN8_RGB.hdfs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segnet biasa Badriayanan\n",
    "def SegNet(input_shape, num_classes):\n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    enc1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    enc1 = tf.keras.layers.BatchNormalization()(enc1)\n",
    "    enc1 = tf.keras.layers.Activation('relu')(enc1)\n",
    "    enc2 = tf.keras.layers.MaxPooling2D()(enc1)\n",
    "    enc2 = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(enc2)\n",
    "    enc2 = tf.keras.layers.BatchNormalization()(enc2)\n",
    "    enc2 = tf.keras.layers.Activation('relu')(enc2)\n",
    "    enc3 = tf.keras.layers.MaxPooling2D()(enc2)\n",
    "    enc3 = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(enc3)\n",
    "    enc3 = tf.keras.layers.BatchNormalization()(enc3)\n",
    "    enc3 = tf.keras.layers.Activation('relu')(enc3)\n",
    "\n",
    "    # Decoder\n",
    "    dec3 = tf.keras.layers.Conv2D(256, (3, 3), padding='same')(enc3)\n",
    "    dec3 = tf.keras.layers.BatchNormalization()(dec3)\n",
    "    dec3 = tf.keras.layers.Activation('relu')(dec3)\n",
    "    dec3 = tf.keras.layers.UpSampling2D()(dec3)\n",
    "    dec2 = tf.keras.layers.Conv2D(128, (3, 3), padding='same')(dec3)\n",
    "    dec2 = tf.keras.layers.BatchNormalization()(dec2)\n",
    "    dec2 = tf.keras.layers.Activation('relu')(dec2)\n",
    "    dec2 = tf.keras.layers.UpSampling2D()(dec2)\n",
    "    dec1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same')(dec2)\n",
    "    dec1 = tf.keras.layers.BatchNormalization()(dec1)\n",
    "    dec1 = tf.keras.layers.Activation('relu')(dec1)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(dec1)\n",
    "\n",
    "    # Define the model\n",
    "    modelS = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return modelS\n",
    "\n",
    "# modelS = SegNet(input_shape=(256, 256, 3), num_classes=4)\n",
    "modelS = SegNet(input_shape=(512, 512, 3), num_classes=3)\n",
    "modelS.compile(optimizer='adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "modelS.summary()\n",
    "\n",
    "# save the model for future use\n",
    "# modelS.save('data/model_save/Segnet.hdfs')\n",
    "# modelS.save('data/model_save/Segnet_256.hdfs')\n",
    "modelS.save('data/model_save/Segnet_RGB.hdfs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AtrousDenseUDeconvNet\n",
    "\n",
    "def A_UnetDense(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    L2 = BatchNormalization()(inputs)\n",
    "    L3 = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(L2)\n",
    "    L4 = Conv2D(8, (3, 3),dilation_rate=2, padding=\"same\")(L3)\n",
    "    L5 = Conv2D(16, (3, 3),dilation_rate=4, padding=\"same\")(L4)\n",
    "    L6 = Conv2D(32, (3, 3),dilation_rate=8, padding=\"same\")(L5)\n",
    "    L7 = Concatenate()([L3, L4, L5, L6])\n",
    "    L8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(L7)\n",
    "    L9 = Dropout(0.1)(L8)\n",
    "    L10 = AveragePooling2D(pool_size=(2, 2))(L9)\n",
    "    L11 = BatchNormalization()(L10)\n",
    "    L12 = Conv2D(32, (3, 3), dilation_rate=2, padding=\"same\")(L11) \n",
    "    L13 = Conv2D(64, (3, 3), dilation_rate=4, padding=\"same\")(L12)\n",
    "    L14 = Conv2D(128, (3, 3), dilation_rate=8, padding=\"same\")(L13)\n",
    "    L15 = Concatenate()([L11, L12, L13, L14])\n",
    "    L16 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(L15)\n",
    "    L17 = Dropout(0.1)(L16)\n",
    "    L18 = AveragePooling2D(pool_size=(2, 2))(L17)\n",
    "    L19 = BatchNormalization()(L18)\n",
    "    L20 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(L19)\n",
    "    L21 = Dropout(0.1)(L20)\n",
    "    L22 = MaxPooling2D(pool_size=(2, 2))(L21)\n",
    "    L23 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(L22)\n",
    "    L24 = Dropout(0.1)(L23)\n",
    "    L25 = MaxPooling2D((2, 2))(L24)\n",
    "    L26 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(L25)\n",
    "    L27 = Dropout(0.1)(L26)\n",
    "    L28 = MaxPooling2D((2, 2))(L27)\n",
    "    L29 = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(L28)\n",
    "    L30 = Dropout(0.1)(L29)\n",
    "    L31 = UpSampling2D()(L30)\n",
    "    L32 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(L31)\n",
    "    L33 = Concatenate()([L27, L32])\n",
    "    L34 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(L33)\n",
    "    L35 = UpSampling2D()(L34)\n",
    "    L36 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(L35)\n",
    "    L37 = Concatenate()([L24, L36])\n",
    "    L38 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(L37)\n",
    "    L39 = UpSampling2D()(L38)\n",
    "    L40 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(L39)\n",
    "    L41 = Concatenate()([L21, L40])\n",
    "    L42 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(L41)\n",
    "    Lt1 = UpSampling2D()(L42)\n",
    "    L43 = Conv2DTranspose(64,(2,2), strides=1, padding='same')(Lt1)\n",
    "    L44 = Conv2DTranspose(64,(2,2), strides=1, padding='same')(L43)\n",
    "    Lt2 = UpSampling2D()(L44)\n",
    "    L45 = Conv2DTranspose(18,(2,2), strides=1, padding='same')(Lt2)\n",
    "    L46 = Conv2DTranspose(6,(2,2), strides=1, padding='same')(L45)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(L46) \n",
    "    \n",
    "    modelA = Model(inputs, outputs, name = 'Model_A_DUDeconvNet')\n",
    "    return modelA\n",
    "\n",
    "# modelA = A_UnetDense(input_shape=(256, 256, 1), num_classes=4)\n",
    "modelA = A_UnetDense(input_shape=(512, 512, 3), num_classes=3)\n",
    "modelA.summary()\n",
    "# save the model for future use\n",
    "# modelA.save('data/model_save/M_ADUDN.hdfs')\n",
    "# modelA.save('data/model_save/M_ADUDN_256.hdfs')\n",
    "modelA.save('data/model_save/M_ADUDN_RGB.hdfs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============= PROGRAM LAIN-LAIN ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, name, ratio=8):\n",
    "    kernel_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "    bias_initializer = tf.constant_initializer(value=0.0)\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        channel = input_feature.get_shape()[-1]\n",
    "        avg_pool = tf.reduce_mean(input_feature, axis=[1, 2], keep_dims=True)\n",
    "\n",
    "        assert avg_pool.get_shape()[1:] == (1, 1, channel)\n",
    "        avg_pool = tf.layers.dense(inputs=avg_pool,\n",
    "                                   units=channel // ratio,\n",
    "                                   activation=tf.nn.relu,\n",
    "                                   kernel_initializer=kernel_initializer,\n",
    "                                   bias_initializer=bias_initializer,\n",
    "                                   name='mlp_0',\n",
    "                                   reuse=None)\n",
    "        assert avg_pool.get_shape()[1:] == (1, 1, channel // ratio)\n",
    "        avg_pool = tf.layers.dense(inputs=avg_pool,\n",
    "                                   units=channel,\n",
    "                                   kernel_initializer=kernel_initializer,\n",
    "                                   bias_initializer=bias_initializer,\n",
    "                                   name='mlp_1',\n",
    "                                   reuse=None)\n",
    "        assert avg_pool.get_shape()[1:] == (1, 1, channel)\n",
    "\n",
    "        max_pool = tf.reduce_max(input_feature, axis=[1, 2], keep_dims=True)\n",
    "        assert max_pool.get_shape()[1:] == (1, 1, channel)\n",
    "        max_pool = tf.layers.dense(inputs=max_pool,\n",
    "                                   units=channel // ratio,\n",
    "                                   activation=tf.nn.relu,\n",
    "                                   name='mlp_0',\n",
    "                                   reuse=True)\n",
    "        assert max_pool.get_shape()[1:] == (1, 1, channel // ratio)\n",
    "        max_pool = tf.layers.dense(inputs=max_pool,\n",
    "                                   units=channel,\n",
    "                                   name='mlp_1',\n",
    "                                   reuse=True)\n",
    "        assert max_pool.get_shape()[1:] == (1, 1, channel)\n",
    "        scale = tf.sigmoid(avg_pool + max_pool, 'sigmoid')\n",
    "\n",
    "\n",
    "    return scale,input_feature * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load SegNet\n",
    "def conv_block(input, num_filters): \n",
    "    x = Conv2D(num_filters, 3, padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Encoder ====\n",
    "def encoder_2block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = conv_block(x num_filters)\n",
    "    p = MaxPooling2D((2,2))(x)\n",
    "    return x, p\n",
    "\n",
    "def encoder_3block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = conv_block(x, num_filters)\n",
    "    x = conv_block(x, num_filters)\n",
    "    p = MaxPooling2D((2,2))(x)\n",
    "    return x, p\n",
    "\n",
    "# Decoder ====\n",
    "def decoder_3block(input, skip_features, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = UpSampling2D()(x)    \n",
    "    return x\n",
    "\n",
    "def decoder_2block(input, skip_features, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = conv_block(input, num_filters)\n",
    "    x = UpSampling2D()(x)    \n",
    "    return x\n",
    "\n",
    "# Build U-Net using the Residu Block\n",
    "def build_Scattnet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    c1, p1 = encoder_2block(inputs, 64)\n",
    "    c2, p2 = encoder_2block(p1, 128)\n",
    "    c3, p3 = encoder_3block(p2, 256)\n",
    "    c4, p4 = encoder_3block(p3, 512)\n",
    "    c5, p5 = encoder_3block(p4, 512)\n",
    "    \n",
    "    b1 = conv_block(p5, 512) #bridge1\n",
    "            \n",
    "    d1 = decoder_3block(b1, c5, 128)\n",
    "    d2 = decoder_3block(d1, c4, 64)\n",
    "    d3 = decoder_3block(d2, c3, 32)\n",
    "    d4 = decoder_1block(d3, c2, 32)\n",
    "    d5 = decoder_1block(d4, c1, 16)\n",
    "    \n",
    "    if n_classes == 1 :\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "    \n",
    "    outputs = Conv2D(n_classes, 1, padding = 'same', activation = activation)(d5) \n",
    "    print(activation)\n",
    "    \n",
    "    model = Model(inputs, outputs, name = 'ScattNet')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load ResNet50 encoder\n",
    "encoder = tf.keras.applications.ResNet50(input_shape=(512, 512, 3), include_top=False, weights='imagenet')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Freeze encoder layers\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    " \n",
    "input_decoder = encoder.get_layer('conv5_block3_out').output\n",
    "\n",
    "# Decoder layers\n",
    "x = MaxPooling2D((2, 2), padding='same')(input_decoder)\n",
    "x = Conv2D(8, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='sigmoid', padding='same')(x) \n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "upconv1 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(upconv1)\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "upconv2 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(upconv2)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "upconv3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(upconv3)\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "upconv4 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(upconv4)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "upconv5 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv9)\n",
    "conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(upconv5)\n",
    "conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv10)\n",
    "conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv10)\n",
    "\n",
    "upconv6 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv10)\n",
    "conv11 = Conv2D(16, (3, 3), activation='relu', padding='same')(upconv6)\n",
    "conv11 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv11)\n",
    "conv11 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv11)\n",
    "\n",
    "upconv7 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv11)\n",
    "conv12 = Conv2D(8, (3, 3), activation='relu', padding='same')(upconv7)\n",
    "conv12 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv12)\n",
    "conv12 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv12)\n",
    "\n",
    "# Output layer\n",
    "output = Conv2D(3, (1, 1), activation='softmax')(conv12)\n",
    "\n",
    "# Define UNet ResNet50 model\n",
    "model1 = Model(inputs=encoder.input, outputs=output)\n",
    "\n",
    "model1.compile(optimizer='adam', loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "# save the model for future use\n",
    "model1.save('data/model_save/ScattNet.hdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================ALTERNATIF MODEL RESNET50 YANG LAIN======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
